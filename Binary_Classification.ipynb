{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bHJ9wq5JXuOO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "dataset_path = \"/content/drive/MyDrive/image_data/dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWzQ4hvmOTVO",
        "outputId": "d984c1bf-3e1c-474e-a6c8-baea3cd97804"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),  # Data Augmentation\n",
        "    transforms.RandomRotation(10),  # Generalizes better\n",
        "    transforms.ToTensor(),     # Convert image to pytorch tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalization\n",
        "    #Centers data around 0, leads to faster convergence\n",
        "])"
      ],
      "metadata": {
        "id": "CDffujX-PMCG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting handcrafted features\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "X, y = [], []\n",
        "for img, label in dataset:\n",
        "    img_np = np.array(img.permute(1, 2, 0) * 255, dtype=np.uint8)  # Convert to NumPy\n",
        "\n",
        "    # Extract HOG features\n",
        "    hog_features = hog(img_np, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                       orientations=9, channel_axis=-1)\n",
        "\n",
        "    # Extract color histogram features\n",
        "    hist_features = cv2.calcHist([img_np], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    hist_features = cv2.normalize(hist_features, hist_features).flatten()\n",
        "\n",
        "    # Concatenate features\n",
        "    feature_vector = np.hstack((hog_features, hist_features))\n",
        "    X.append(feature_vector)\n",
        "    y.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHGT6qTkyUdy",
        "outputId": "8f8a003f-6934-45e6-938c-e58bf4dec47e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split for random forest and svm\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "656kIis_ydcB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for SVM\n",
        "svm_param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
        "svm_clf = RandomizedSearchCV(SVC(), svm_param_grid, n_iter=10, cv=3, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qnNPB9Nyk7n",
        "outputId": "c09b6553-0bcb-4db3-8a52-be2848109184"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 91.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Random Forest\n",
        "rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
        "rf_clf = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, n_iter=10, cv=3, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {rf_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Zg9gtuy7Qy",
        "outputId": "dc9811b6-dcac-4c0a-c984-9f24f3fec0d6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 87.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for cnn\n",
        "full_data = datasets.ImageFolder(root=dataset_path, transform=transform) # Automatically assigns label based on folder name\n",
        "train_size = int(0.8 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "train_data, test_data = random_split(full_data, [train_size, test_size])"
      ],
      "metadata": {
        "id": "DGfdEVFrPzpW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)   # Makes mini-batches of size 32\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "P6qe7Mu7P4XE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 8 * 8, 128), # 64 are the filters and 8*8 is the spatial dimension ( because of prev layers )\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2)  # Binary classification (Mask / No Mask)\n",
        ")\n",
        "# Note: No. of output channels is a design choice\n",
        "# Just one FC layer afte conv layers is enough more layers may introduce overfitting"
      ],
      "metadata": {
        "id": "SJmyAXmBP6pb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GNzG61tP9dL",
        "outputId": "399d4da9-077c-4b9a-a3a8-9b245baca615"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): ReLU()\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Initial learning rate, adam optimizer automatically adjusts learning rate"
      ],
      "metadata": {
        "id": "3YElD3hiP_vL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # reset gradients to ensure, results from prev iterations don't accumulate\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step() #updates weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq34FGGCQCYl",
        "outputId": "514ffa78-0334-4838-e89c-c7e0c8684944"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.2447\n",
            "Epoch 2/10, Loss: 0.1741\n",
            "Epoch 3/10, Loss: 0.1450\n",
            "Epoch 4/10, Loss: 0.1269\n",
            "Epoch 5/10, Loss: 0.0984\n",
            "Epoch 6/10, Loss: 0.0957\n",
            "Epoch 7/10, Loss: 0.0808\n",
            "Epoch 8/10, Loss: 0.0751\n",
            "Epoch 9/10, Loss: 0.0678\n",
            "Epoch 10/10, Loss: 0.0566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "cnn_acc = 100 * correct / total\n",
        "print(f\" Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/mask_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfPM3T36QG9L",
        "outputId": "1bab608c-95e3-4470-932d-16622f1950d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test Accuracy: 96.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Results\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")\n",
        "print(f\"Random Forest Accuracy: {rf_acc * 100:.2f}%\")\n",
        "print(f\"CNN Accuracy: {cnn_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-xMNOoVzC_r",
        "outputId": "d394b51e-07df-4c0d-baa1-2fcff8710b21"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "SVM Accuracy: 91.70%\n",
            "Random Forest Accuracy: 87.42%\n",
            "CNN Accuracy: 96.95%\n"
          ]
        }
      ]
    }
  ]
}