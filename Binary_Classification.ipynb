{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bHJ9wq5JXuOO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "dataset_path = \"/content/drive/MyDrive/image_data/dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWzQ4hvmOTVO",
        "outputId": "9646c76e-ef6b-4c6d-c448-69159f3475c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),  # Data Augmentation\n",
        "    transforms.RandomRotation(10),  # Generalizes better\n",
        "    transforms.ToTensor(),     # Convert image to pytorch tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalization\n",
        "    #Centers data around 0, leads to faster convergence\n",
        "])"
      ],
      "metadata": {
        "id": "CDffujX-PMCG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting handcrafted features\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "X, y = [], []\n",
        "for img, label in dataset:\n",
        "    img_np = np.array(img.permute(1, 2, 0) * 255, dtype=np.uint8)  # Convert to NumPy\n",
        "\n",
        "    # Extract HOG features\n",
        "    hog_features = hog(img_np, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                       orientations=9, channel_axis=-1)\n",
        "\n",
        "    # Extract color histogram features\n",
        "    hist_features = cv2.calcHist([img_np], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    hist_features = cv2.normalize(hist_features, hist_features).flatten()\n",
        "\n",
        "    # Concatenate features\n",
        "    feature_vector = np.hstack((hog_features, hist_features))\n",
        "    X.append(feature_vector)\n",
        "    y.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHGT6qTkyUdy",
        "outputId": "c0f4ad2a-f464-4668-e52d-2c1da399b04e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split for random forest and svm\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "656kIis_ydcB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for SVM\n",
        "svm_param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
        "svm_clf = RandomizedSearchCV(SVC(), svm_param_grid, n_iter=10, cv=3, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qnNPB9Nyk7n",
        "outputId": "caa5e63c-a6e8-4f94-8636-457c7db43890"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 91.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Random Forest\n",
        "rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
        "rf_clf = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, n_iter=10, cv=3, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {rf_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Zg9gtuy7Qy",
        "outputId": "bd136990-1858-416d-a251-57ee6280c0cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 88.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for cnn\n",
        "full_data = datasets.ImageFolder(root=dataset_path, transform=transform) # Automatically assigns label based on folder name\n",
        "train_size = int(0.8 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "train_data, test_data = random_split(full_data, [train_size, test_size])"
      ],
      "metadata": {
        "id": "DGfdEVFrPzpW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)   # Makes mini-batches of size 32\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "P6qe7Mu7P4XE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 8 * 8, 128), # 64 are the filters and 8*8 is the spatial dimension ( because of prev layers )\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2)  # Binary classification (Mask / No Mask)\n",
        ")\n",
        "# Note: No. of output channels is a design choice\n",
        "# Just one FC layer afte conv layers is enough more layers may introduce overfitting"
      ],
      "metadata": {
        "id": "SJmyAXmBP6pb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GNzG61tP9dL",
        "outputId": "a22a7e10-58eb-4e18-ccda-bf5b843dadee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): ReLU()\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Initial learning rate, adam optimizer automatically adjusts learning rate"
      ],
      "metadata": {
        "id": "3YElD3hiP_vL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # reset gradients to ensure, results from prev iterations don't accumulate\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step() #updates weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq34FGGCQCYl",
        "outputId": "f1de8dac-8897-420f-a2eb-3050e8db87f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.3930\n",
            "Epoch 2/10, Loss: 0.2469\n",
            "Epoch 3/10, Loss: 0.1739\n",
            "Epoch 4/10, Loss: 0.1394\n",
            "Epoch 5/10, Loss: 0.1178\n",
            "Epoch 6/10, Loss: 0.0989\n",
            "Epoch 7/10, Loss: 0.0940\n",
            "Epoch 8/10, Loss: 0.0764\n",
            "Epoch 9/10, Loss: 0.0714\n",
            "Epoch 10/10, Loss: 0.0647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "cnn_acc = 100 * correct / total\n",
        "print(f\" Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/mask_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfPM3T36QG9L",
        "outputId": "1a60955f-1343-4b7b-ca0f-38f5b23d8456"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test Accuracy: 95.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(len(X_train[0]), 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 2)\n",
        ")\n",
        "mlp.to(device)\n",
        "mlp_criterion = nn.CrossEntropyLoss()\n",
        "mlp_optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "SoLM3l3oOKvn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChqCPGZHOoH0",
        "outputId": "441254d9-75ef-477e-af0c-15e46594cf8c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-6c5cfcaf2222>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    mlp.train()\n",
        "    mlp_optimizer.zero_grad()\n",
        "    outputs = mlp(X_train_tensor)\n",
        "    loss = mlp_criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    mlp_optimizer.step()\n",
        "    print(f\"MLP Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "mlp.eval()\n",
        "with torch.no_grad():\n",
        "    mlp_outputs = mlp(X_test_tensor)\n",
        "    _, mlp_predicted = torch.max(mlp_outputs, 1)\n",
        "mlp_acc = accuracy_score(y_test, mlp_predicted.cpu().numpy()) * 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUAbIxr7Or3V",
        "outputId": "16e7779c-fc44-482f-ec1d-3221a6eaf752"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Epoch 1/10, Loss: 0.6943\n",
            "MLP Epoch 2/10, Loss: 0.6902\n",
            "MLP Epoch 3/10, Loss: 0.6861\n",
            "MLP Epoch 4/10, Loss: 0.6817\n",
            "MLP Epoch 5/10, Loss: 0.6762\n",
            "MLP Epoch 6/10, Loss: 0.6695\n",
            "MLP Epoch 7/10, Loss: 0.6619\n",
            "MLP Epoch 8/10, Loss: 0.6531\n",
            "MLP Epoch 9/10, Loss: 0.6432\n",
            "MLP Epoch 10/10, Loss: 0.6321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Results\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")\n",
        "print(f\"Random Forest Accuracy: {rf_acc * 100:.2f}%\")\n",
        "print(f\"CNN Accuracy: {cnn_acc:.2f}%\")\n",
        "print(f\"MLP Accuracy: {mlp_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-xMNOoVzC_r",
        "outputId": "e5c3b3ac-0b69-42bb-dea2-d4095501b9aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "SVM Accuracy: 91.45%\n",
            "Random Forest Accuracy: 88.89%\n",
            "CNN Accuracy: 95.73%\n",
            "MLP Accuracy: 80.95%\n"
          ]
        }
      ]
    }
  ]
}